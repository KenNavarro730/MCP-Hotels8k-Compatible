{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2bc979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import random\n",
    "import torchvision\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(annotation_file='instances_train2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9a4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider concept combinations seen in at least 8/2/2 images in the train/val/test splits.\n",
    "number_train = 8\n",
    "number_val = 2\n",
    "number_test = 2\n",
    "k=2 # Number of concepts being combined\n",
    "n_combinations = 1000 #seen combinations\n",
    "n_combinations_zero_shot = 250 #unseen category combinations\n",
    "\n",
    "#The train set contains 4/6ths of the images, and test and validation contain 1/6th each.\n",
    "def get_train_subset(img_list):\n",
    "    return [x for x in img_list if x%6==0 or x%6==1 or x%6==2 or x%6==3]\n",
    "\n",
    "def get_val_subset(img_list):\n",
    "    return [x for x in img_list if x%6==4]\n",
    "\n",
    "def get_test_subset(img_list):\n",
    "    return [x for x in img_list if x%6==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af004d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = coco.getCatIds()\n",
    "hash_table_category_tuples = {}\n",
    "combinations = []\n",
    "while len(combinations) < n_combinations:\n",
    "    print(len(combinations))\n",
    "    cat_ids = sorted(random.sample(cats, k=k))\n",
    "    img_ids = coco.getImgIds(catIds=cat_ids)\n",
    "    img_ids_train = get_train_subset(img_ids)\n",
    "    img_ids_val = get_val_subset(img_ids)\n",
    "    img_ids_test = get_test_subset(img_ids)\n",
    "    if len(img_ids_train) >= number_train and len(img_ids_val) >= number_val and len(img_ids_test) >= number_test:\n",
    "        hash_code_cats = '_'.join([str(c) for c in cat_ids])\n",
    "        if hash_code_cats not in hash_table_category_tuples:\n",
    "            hash_table_category_tuples[hash_code_cats] = True\n",
    "            combinations.append(cat_ids)\n",
    "        else:\n",
    "            print('already seen')\n",
    "    else:\n",
    "        print('not enough images')\n",
    "\n",
    "# generate a new set of unseen category combinations for zero shot experiments \n",
    "seen = set([i for c in combinations for i in c])\n",
    "combinations_zero_shot = []\n",
    "while len(combinations_zero_shot) < n_combinations_zero_shot:\n",
    "    print(len(combinations_zero_shot))\n",
    "    cat_ids = sorted(random.sample(seen, k=k))\n",
    "    img_ids = coco.getImgIds(catIds=cat_ids)\n",
    "    img_ids_train = get_train_subset(img_ids)\n",
    "    img_ids_val = get_val_subset(img_ids)\n",
    "    img_ids_test = get_test_subset(img_ids)\n",
    "    if len(img_ids_train) >= number_train and len(img_ids_val) >= number_val and len(img_ids_test) >= number_test:\n",
    "        hash_code_cats = '_'.join([str(c) for c in cat_ids])\n",
    "        if hash_code_cats not in hash_table_category_tuples:\n",
    "            hash_table_category_tuples[hash_code_cats] = True\n",
    "            combinations_zero_shot.append(cat_ids)\n",
    "        else:\n",
    "            print('already seen')\n",
    "    else:\n",
    "        print('not enough images')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a set of impossible combinations for feasibility experiments\n",
    "n_combinations_impossible = 250 #impossible combinations\n",
    "combinations_impossible = []\n",
    "hash_table_category_tuples_impossible = {}\n",
    "\n",
    "while len(combinations_impossible) < n_combinations_impossible:\n",
    "    print(len(combinations_impossible))\n",
    "    cat_ids = sorted(random.sample(cats, k=k))\n",
    "    img_ids = coco.getImgIds(catIds=cat_ids)\n",
    "    img_ids_train = get_train_subset(img_ids)\n",
    "    img_ids_val = get_val_subset(img_ids)\n",
    "    img_ids_test = get_test_subset(img_ids)\n",
    "    \n",
    "    if len(img_ids) == 0:\n",
    "        print([x['name'] for x in coco.loadCats(cat_ids)])\n",
    "        hash_code_cats = '_'.join([str(c) for c in cat_ids])\n",
    "        if hash_code_cats not in hash_table_category_tuples_impossible:\n",
    "            hash_table_category_tuples_impossible[hash_code_cats] = True\n",
    "            combinations_impossible.append(cat_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5229182",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2_cat_combinations.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(combinations, f, ensure_ascii=False, indent=4)\n",
    "with open('2_cat_combinations_zero_shot.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(combinations_zero_shot, f, ensure_ascii=False, indent=4)\n",
    "with open('2_cat_combinations_impossible.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(combinations_impossible, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train/test/val image splits\n",
    "img_ids = coco.getImgIds()\n",
    "img_ids_train = get_train_subset(img_ids)\n",
    "img_ids_val = get_val_subset(img_ids)\n",
    "img_ids_test = get_test_subset(img_ids)\n",
    "\n",
    "with open('train_imgs.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(img_ids_train, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('test_imgs.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(img_ids_test, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "with open('val_imgs.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(img_ids_val, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08241778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute the lists of images for all combinations of concepts. \n",
    "# We do this to speed up processing during training/evaluation.\n",
    "\n",
    "img_ids_per_cat_train = {}\n",
    "img_ids_per_cat_test = {}\n",
    "img_ids_per_cat_val = {}\n",
    "print(cats)\n",
    "for cat in tqdm(cats):\n",
    "    img_ids = coco.getImgIds(catIds=cat)\n",
    "    img_ids_train = get_train_subset(img_ids)\n",
    "    img_ids_val = get_val_subset(img_ids)\n",
    "    img_ids_test = get_test_subset(img_ids)\n",
    "    img_ids_per_cat_train[cat] = img_ids_train\n",
    "    img_ids_per_cat_val[cat] = img_ids_val    \n",
    "    img_ids_per_cat_test[cat] = img_ids_test\n",
    "\n",
    "for cats in tqdm(combinations):\n",
    "    img_ids = coco.getImgIds(catIds=cats)\n",
    "    img_ids_train = get_train_subset(img_ids)\n",
    "    img_ids_val = get_val_subset(img_ids)\n",
    "    img_ids_test = get_test_subset(img_ids)\n",
    "    hash_code = '_'.join([str(x) for x in cats])\n",
    "    img_ids_per_cat_train[hash_code] = img_ids_train\n",
    "    img_ids_per_cat_val[hash_code] = img_ids_val    \n",
    "    img_ids_per_cat_test[hash_code] = img_ids_test\n",
    "\n",
    "for cats in tqdm(combinations_zero_shot):\n",
    "    img_ids = coco.getImgIds(catIds=cats)\n",
    "    img_ids_train = get_train_subset(img_ids)\n",
    "    img_ids_val = get_val_subset(img_ids)\n",
    "    img_ids_test = get_test_subset(img_ids)\n",
    "    hash_code = '_'.join([str(x) for x in cats])\n",
    "    img_ids_per_cat_train[hash_code] = img_ids_train\n",
    "    img_ids_per_cat_val[hash_code] = img_ids_val    \n",
    "    img_ids_per_cat_test[hash_code] = img_ids_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065fc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2_img_ids_per_cats_train.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(img_ids_per_cat_train, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('2_img_ids_per_cats_val.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(img_ids_per_cat_val, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "with open('2_img_ids_per_cats_test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(img_ids_per_cat_test, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test cases for both seen and unseen combinations scenarios\n",
    "\n",
    "test_cases_per_combination = 100\n",
    "testset = []\n",
    "valset = []\n",
    "testset_zero_shot = []\n",
    "valset_zero_shot = []\n",
    "\n",
    "#testset\n",
    "for cats in tqdm(combinations):\n",
    "    image_ids_per_cat = []\n",
    "    for cat in cats:\n",
    "        img_ids = random.choices(get_test_subset(coco.getImgIds(catIds=cat)), k = test_cases_per_combination)\n",
    "        image_ids_per_cat.append(img_ids)\n",
    "    test_img_sets = [list(x) for x in zip(*image_ids_per_cat)]\n",
    "    for test_img_set in test_img_sets:\n",
    "        test_case = {}\n",
    "        test_case['images'] = test_img_set\n",
    "        test_case['categories'] = cats\n",
    "        test_case['modalities'] = random.choices(['image', 'text'], k=len(test_img_set))\n",
    "        testset.append(test_case)\n",
    "\n",
    "#valset\n",
    "for cats in tqdm(combinations):\n",
    "    image_ids_per_cat = []\n",
    "    for cat in cats:\n",
    "        img_ids = random.choices(get_val_subset(coco.getImgIds(catIds=cat)), k = test_cases_per_combination)\n",
    "        image_ids_per_cat.append(img_ids)\n",
    "    test_img_sets = [list(x) for x in zip(*image_ids_per_cat)]\n",
    "    for test_img_set in test_img_sets:\n",
    "        test_case = {}\n",
    "        test_case['images'] = test_img_set\n",
    "        test_case['categories'] = cats\n",
    "        test_case['modalities'] = random.choices(['image', 'text'], k=len(test_img_set))\n",
    "        valset.append(test_case)\n",
    "\n",
    "#testset zero shot\n",
    "for cats in tqdm(combinations_zero_shot):\n",
    "    image_ids_per_cat = []\n",
    "    for cat in cats:\n",
    "        img_ids = random.choices(get_test_subset(coco.getImgIds(catIds=cat)), k = test_cases_per_combination)\n",
    "        image_ids_per_cat.append(img_ids)\n",
    "    test_img_sets = [list(x) for x in zip(*image_ids_per_cat)]\n",
    "    for test_img_set in test_img_sets:\n",
    "        test_case = {}\n",
    "        test_case['images'] = test_img_set\n",
    "        test_case['categories'] = cats\n",
    "        test_case['modalities'] = random.choices(['image', 'text'], k=len(test_img_set))\n",
    "        testset_zero_shot.append(test_case)\n",
    "\n",
    "#valset zero shot\n",
    "for cats in tqdm(combinations_zero_shot):\n",
    "    image_ids_per_cat = []\n",
    "    for cat in cats:\n",
    "        img_ids = random.choices(get_val_subset(coco.getImgIds(catIds=cat)), k = test_cases_per_combination)\n",
    "        image_ids_per_cat.append(img_ids)\n",
    "    test_img_sets = [list(x) for x in zip(*image_ids_per_cat)]\n",
    "    for test_img_set in test_img_sets:\n",
    "        test_case = {}\n",
    "        test_case['images'] = test_img_set\n",
    "        test_case['categories'] = cats\n",
    "        test_case['modalities'] = random.choices(['image', 'text'], k=len(test_img_set))\n",
    "        valset_zero_shot.append(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the test cases in a way that will be easily parsed during training/evaluation\n",
    "\n",
    "formatted_testset = {}\n",
    "for elem in testset:\n",
    "    hash_code = '_'.join(elem['modalities'])\n",
    "    if hash_code not in formatted_testset:\n",
    "        formatted_testset[hash_code] = []\n",
    "    formatted_testset[hash_code].append({\n",
    "        'images': elem['images'],\n",
    "        'categories': elem['categories']\n",
    "    })\n",
    "    \n",
    "formatted_valset = {}\n",
    "for elem in valset:\n",
    "    hash_code = '_'.join(elem['modalities'])\n",
    "    if hash_code not in formatted_valset:\n",
    "        formatted_valset[hash_code] = []\n",
    "    formatted_valset[hash_code].append({\n",
    "        'images': elem['images'],\n",
    "        'categories': elem['categories']\n",
    "    })\n",
    "\n",
    "formatted_testset_zero_shot = {}\n",
    "for elem in testset_zero_shot:\n",
    "    hash_code = '_'.join(elem['modalities'])\n",
    "    if hash_code not in formatted_testset_zero_shot:\n",
    "        formatted_testset_zero_shot[hash_code] = []\n",
    "    formatted_testset_zero_shot[hash_code].append({\n",
    "        'images': elem['images'],\n",
    "        'categories': elem['categories']\n",
    "    })\n",
    "    \n",
    "formatted_valset_zero_shot = {}\n",
    "for elem in valset_zero_shot:\n",
    "    hash_code = '_'.join(elem['modalities'])\n",
    "    if hash_code not in formatted_valset_zero_shot:\n",
    "        formatted_valset_zero_shot[hash_code] = []\n",
    "    formatted_valset_zero_shot[hash_code].append({\n",
    "        'images': elem['images'],\n",
    "        'categories': elem['categories']\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2_test_cases.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(formatted_testset, f, ensure_ascii=False, indent=4)\n",
    "with open('2_val_cases.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(formatted_valset, f, ensure_ascii=False, indent=4)\n",
    "with open('2_test_cases_zero_shot.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(formatted_testset_zero_shot, f, ensure_ascii=False, indent=4)\n",
    "with open('2_val_cases_zero_shot.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(formatted_valset_zero_shot, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
